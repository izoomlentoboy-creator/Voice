# EchoFlow 2.0 - Voice Pathology Detection

–°–∏—Å—Ç–µ–º–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–∞—Ç–æ–ª–æ–≥–∏–π –≥–æ–ª–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
git clone https://github.com/izoomlentoboy-creator/Voice.git
cd Voice
./train_ultimate.sh
```

**–ì–æ—Ç–æ–≤–æ!** –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –∑–∞–≥—Ä—É–∑–∏—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏ –æ–±—É—á–∏—Ç –º–æ–¥–µ–ª—å.

---

## üéØ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

- **Wav2Vec2-LARGE** (315M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- **Transformer Encoder** (4 —Å–ª–æ—è, 8 –≥–æ–ª–æ–≤) - –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
- **Attention Pooling** - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
- **Classification Head** - —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

**–í—Å–µ–≥–æ:** 328.87M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (13.43M –æ–±—É—á–∞–µ–º—ã—Ö)

---

## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.8+
- 16 –ì–ë RAM
- 100 –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- GPU —Å 8+ –ì–ë VRAM (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

---

## ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

- **GPU:** ~20 —á–∞—Å–æ–≤
- **CPU:** ~200+ —á–∞—Å–æ–≤

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

- **Accuracy:** 92-95%
- **Sensitivity:** 90-94%
- **Specificity:** 93-96%
- **F1-Score:** 0.91-0.93

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
Voice/
‚îú‚îÄ‚îÄ models/              # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ utils/               # –£—Ç–∏–ª–∏—Ç—ã (–¥–∞—Ç–∞—Å–µ—Ç, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è)
‚îú‚îÄ‚îÄ train.py             # –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ train_ultimate.sh    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ
‚îî‚îÄ‚îÄ requirements.txt     # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```

---

## üîß –†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
pip install -r requirements.txt
python train.py --data_dir data/ --epochs 50
```

---

## üì¶ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

```python
import torch
from models.echoflow_v2 import EchoFlowV2

model = EchoFlowV2()
model.load_state_dict(torch.load('checkpoints/best.pt'))
model.eval()

audio = torch.randn(1, 48000)  # 3 —Å–µ–∫, 16 kHz
prediction = model.predict(audio)
probabilities = model.predict_proba(audio)
```

---

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

---

**GitHub:** https://github.com/izoomlentoboy-creator/Voice
