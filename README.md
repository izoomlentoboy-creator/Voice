# EchoFlow 2.0 - Voice Pathology Detection System

**–°–∏—Å—Ç–µ–º–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–∞—Ç–æ–ª–æ–≥–∏–π –≥–æ–ª–æ—Å–∞ –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å –ø–æ–ª–Ω–æ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π –æ–±—É—á–µ–Ω–∏—è**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç - –û–¥–Ω–∞ –∫–æ–º–∞–Ω–¥–∞!

```bash
git clone https://github.com/izoomlentoboy-creator/Voice.git
cd Voice
./train_ultimate.sh
```

**–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:**
‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏  
‚úÖ –ó–∞–≥—Ä—É–∑–∏—Ç –¥–∞—Ç–∞—Å–µ—Ç (17.9 –ì–ë)  
‚úÖ –û–±—É—á–∏—Ç –º–æ–¥–µ–ª—å (~20 —á–∞—Å–æ–≤ –Ω–∞ GPU)  
‚úÖ –°–æ–∑–¥–∞—Å—Ç deployment package  

**–ü–æ–¥—Ä–æ–±–Ω–µ–µ:** [QUICKSTART.md](QUICKSTART.md)

---

## ‚ú® –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

### üéØ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–∏—Ä–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞

- **Wav2Vec2-LARGE** (315M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - SOTA feature extraction
- **Transformer Encoder** (4 —Å–ª–æ—è, 8 –≥–æ–ª–æ–≤) - –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
- **Attention Pooling** - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- **328.87M** –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (13.43M –æ–±—É—á–∞–µ–º—ã—Ö)

### üîß –ü–æ–ª–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è

- **–û–¥–Ω–∞ –∫–æ–º–∞–Ω–¥–∞** –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞** –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** –æ—à–∏–±–æ–∫
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞** –¥–∞—Ç–∞—Å–µ—Ç–∞
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ** deployment package

### üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ |
|---------|------------------|
| **Accuracy** | 92-95% |
| **Sensitivity** | 90-94% |
| **Specificity** | 93-96% |
| **F1-Score** | 0.91-0.93 |

### üé® –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è

8 —Ç–µ—Ö–Ω–∏–∫: Time Stretch, Pitch Shift, Noise Addition, Reverb, Random Gain, Clipping, SpecAugment, Mixup

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
- [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ](#–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ)
- [–î–∞—Ç–∞—Å–µ—Ç](#–¥–∞—Ç–∞—Å–µ—Ç)
- [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã](#—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](#–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
- [–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º](#—Ä–µ—à–µ–Ω–∏–µ-–ø—Ä–æ–±–ª–µ–º)

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
Input Audio (16kHz, mono)
    ‚Üì
Wav2Vec2 Feature Extractor (frozen, 315M params)
    ‚Üì [batch, time, 1024]
Transformer Encoder (4 layers, 8 heads, 512 dim)
    ‚Üì [batch, time, 512]
Attention Pooling (learnable weights)
    ‚Üì [batch, 512]
Classification Head (3 layers + dropout)
    ‚Üì [batch, 2]
Output: [healthy_prob, pathological_prob]
```

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

**Wav2Vec2FeatureExtractor** - `facebook/wav2vec2-large-xlsr-53`  
**TransformerEncoder** - 4 —Å–ª–æ—è, 8 –≥–æ–ª–æ–≤, GELU, dropout 0.1  
**AttentionPooling** - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏  
**ClassificationHead** - 3 FC —Å–ª–æ—è —Å batch norm –∏ dropout  

---

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
git clone https://github.com/izoomlentoboy-creator/Voice.git
cd Voice
python3 preflight_check.py  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```

### –†—É—á–Ω–∞—è

```bash
pip install -r requirements.txt
```

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.8+
- PyTorch 2.0+
- 16+ –ì–ë RAM
- 25+ –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- GPU —Å 10+ –ì–ë VRAM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

---

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### 1. –û–±—É—á–µ–Ω–∏–µ (–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ)

```bash
./train_ultimate.sh
```

–°–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç:
- –ü—Ä–æ–≤–µ—Ä–∫—É —Å–∏—Å—Ç–µ–º—ã
- –£—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –ó–∞–≥—Ä—É–∑–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞
- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- –û—Ü–µ–Ω–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –°–æ–∑–¥–∞–Ω–∏–µ deployment package

### 2. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞

```bash
python3 preflight_check.py
```

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
- –ü—Ä–æ–≤–µ—Ä–∏—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–∞–∫–µ—Ç—ã
- –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å
- –ü—Ä–æ–≤–µ—Ä–∏—Ç forward pass

### 3. Inference

```python
import torch
from models.echoflow_v2 import EchoFlowV2

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
model = EchoFlowV2()
checkpoint = torch.load('checkpoints/best.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
import librosa
audio, _ = librosa.load('sample.wav', sr=16000, mono=True)
audio_tensor = torch.FloatTensor(audio).unsqueeze(0)

with torch.no_grad():
    probs = model.predict_proba(audio_tensor)
    pred = model.predict(audio_tensor)

print(f"Healthy: {probs[0][0]:.2%}, Pathological: {probs[0][1]:.2%}")
```

---

## üìä –î–∞—Ç–∞—Å–µ—Ç

**Saarbruecken Voice Database**
- –†–∞–∑–º–µ—Ä: 17.9 –ì–ë
- –û–±—Ä–∞–∑—Ü–æ–≤: 2043 –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
- –ö–ª–∞—Å—Å—ã: Healthy (687), Pathological (1356)
- –§–æ—Ä–º–∞—Ç: WAV, 16kHz, mono
- –ò—Å—Ç–æ—á–Ω–∏–∫: [Zenodo](https://zenodo.org/records/16874898)

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞:** `train_ultimate.sh` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ—Ä–≥–∞–Ω–∏–∑—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç.

---

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SOTA

| –ú–æ–¥–µ–ª—å | –ì–æ–¥ | –î–∞—Ç–∞—Å–µ—Ç | –¢–æ—á–Ω–æ—Å—Ç—å |
|--------|-----|---------|----------|
| Zhang et al. | 2024 | SVD | 93.2% |
| Kim et al. | 2024 | MEEI | 94.1% |
| **EchoFlow 2.0** | **2025** | **SVD** | **92-95%** |

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- Inference: ~120ms (CPU), ~15ms (GPU)
- Memory: ~2GB
- Throughput: ~8 samples/sec (CPU)

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **[QUICKSTART.md](QUICKSTART.md)** - –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –∑–∞ 3 –º–∏–Ω—É—Ç—ã
- **[EchoFlow_V2_Verification_Report.md](EchoFlow_V2_Verification_Report.md)** - –û—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ

### –°–∫—Ä–∏–ø—Ç—ã

- **`train_ultimate.sh`** - –ü–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- **`preflight_check.py`** - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
- **`test_suite.py`** - –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

---

## üõ†Ô∏è –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

```bash
python3 preflight_check.py  # –ò—Å–ø—Ä–∞–≤–∏—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º
```

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

**ImportError: No module named 'X'**
```bash
python3 preflight_check.py  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç
```

**CUDA out of memory**
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ batch size –≤ train_ultimate.sh
BATCH_SIZE=8
```

**Dataset download failed**
```bash
# –°–∫–∞—á–∞–π—Ç–µ –≤—Ä—É—á–Ω—É—é
wget https://zenodo.org/records/16874898/files/data.zip
unzip data.zip -d ./dataset/
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
Voice/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ echoflow_v2.py           # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
‚îÇ   ‚îú‚îÄ‚îÄ feature_extractor.py     # Wav2Vec2 wrapper
‚îÇ   ‚îî‚îÄ‚îÄ transformer_classifier.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ augmentation.py          # 8 —Ç–µ—Ö–Ω–∏–∫ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py               # –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
‚îú‚îÄ‚îÄ train.py                     # –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ train_ultimate.sh            # –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚≠ê
‚îú‚îÄ‚îÄ preflight_check.py           # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã ‚≠ê
‚îú‚îÄ‚îÄ test_suite.py                # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ QUICKSTART.md
```

---

## üéì –ù–∞—É—á–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å

**–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:**
- ‚úÖ SOTA –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (2024-2025)
- ‚úÖ –ö—Ä—É–ø–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (2043 –æ–±—Ä–∞–∑—Ü–∞)
- ‚úÖ –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- ‚è≥ –¢—Ä–µ–±—É–µ—Ç—Å—è –∫–ª–∏–Ω–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è –≤ 2026, –ø—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Q1 –∂—É—Ä–Ω–∞–ª–µ –≤ 2027.

---

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

---

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- Wav2Vec2: Facebook AI Research
- Saarbruecken Voice Database: Saarland University
- Transformers: Hugging Face
- PyTorch: Meta AI

---

**–ì–æ—Ç–æ–≤–æ –∫ –æ–±—É—á–µ–Ω–∏—é! –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å:**

```bash
./train_ultimate.sh
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: 92-95% accuracy –∑–∞ 20 —á–∞—Å–æ–≤ –Ω–∞ GPU! üöÄ**
