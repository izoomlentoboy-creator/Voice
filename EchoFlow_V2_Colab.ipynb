{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EchoFlow 2.0 - Voice Pathology Detection\n",
    "\n",
    "**–°–∏—Å—Ç–µ–º–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–∞—Ç–æ–ª–æ–≥–∏–π –≥–æ–ª–æ—Å–∞ –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è**\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
    "\n",
    "**–≠—Ç–æ—Ç notebook:**\n",
    "- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ\n",
    "- ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "- ‚úÖ –ó–∞–≥—Ä—É–∑–∏—Ç –¥–∞—Ç–∞—Å–µ—Ç (17.9 –ì–ë)\n",
    "- ‚úÖ –û–±—É—á–∏—Ç –º–æ–¥–µ–ª—å (~20 —á–∞—Å–æ–≤ –Ω–∞ GPU T4)\n",
    "- ‚úÖ –°–æ–∑–¥–∞—Å—Ç deployment package\n",
    "\n",
    "**–ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏!**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "\n",
    "**–ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º:**\n",
    "1. Runtime ‚Üí Change runtime type ‚Üí **GPU T4**\n",
    "2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ GPU –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω\n",
    "3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏: Runtime ‚Üí Run all\n",
    "\n",
    "---\n",
    "\n",
    "## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "- **Accuracy:** 92-95%\n",
    "- **Sensitivity:** 90-94%\n",
    "- **Specificity:** 93-96%\n",
    "- **F1-Score:** 0.91-0.93\n",
    "- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** ~20 —á–∞—Å–æ–≤ –Ω–∞ GPU T4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  GPU Check\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"\\n‚úÖ Ready for training!\")\n",
    "else:\n",
    "    print(\"‚ö† WARNING: No GPU detected!\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU T4\")\n",
    "    print(\"Training on CPU will be VERY slow (~200+ hours)\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Cloning Repository\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "if os.path.exists('/content/Voice'):\n",
    "    !rm -rf /content/Voice\n",
    "    print(\"‚úì Removed old version\")\n",
    "\n",
    "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
    "!git clone https://github.com/izoomlentoboy-creator/Voice.git /content/Voice\n",
    "\n",
    "# –ü–µ—Ä–µ–π—Ç–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "%cd /content/Voice\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"  Installing Dependencies\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è librosa\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq libsndfile1 ffmpeg\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Python –ø–∞–∫–µ—Ç—ã\n",
    "!pip install -q transformers librosa soundfile scipy scikit-learn tqdm protobuf sentencepiece\n",
    "\n",
    "print(\"\\n‚úÖ Dependencies installed successfully!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤\n",
    "print(\"\\nInstalled packages:\")\n",
    "import transformers\n",
    "import librosa\n",
    "import scipy\n",
    "import sklearn\n",
    "print(f\"‚úì PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úì Transformers: {transformers.__version__}\")\n",
    "print(f\"‚úì Librosa: {librosa.__version__}\")\n",
    "print(f\"‚úì SciPy: {scipy.__version__}\")\n",
    "print(f\"‚úì Scikit-learn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/Voice')\n",
    "\n",
    "from models.echoflow_v2 import EchoFlowV2, count_parameters\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Model Architecture Check\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "model = EchoFlowV2(freeze_wav2vec2=True)\n",
    "params = count_parameters(model)\n",
    "\n",
    "print(f\"\\n‚úì Total Parameters:    {params['total_millions']:.2f}M\")\n",
    "print(f\"‚úì Trainable:           {params['trainable_millions']:.2f}M\")\n",
    "print(f\"‚úì Frozen (Wav2Vec2):   {params['frozen_millions']:.2f}M\")\n",
    "\n",
    "# –¢–µ—Å—Ç forward pass\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "audio = torch.randn(2, 48000).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(audio)\n",
    "    probs = model.predict_proba(audio)\n",
    "\n",
    "print(f\"\\n‚úì Forward Pass:        {audio.shape} ‚Üí {logits.shape}\")\n",
    "print(f\"‚úì Probabilities:       {probs[0].cpu().tolist()}\")\n",
    "print(f\"‚úì Device:              {device}\")\n",
    "\n",
    "print(\"\\n‚úÖ Model architecture verified!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "**‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ:** –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–π–º–µ—Ç ~15-20 –º–∏–Ω—É—Ç (17.9 –ì–ë)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Dataset Download\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "dataset_dir = '/content/dataset'\n",
    "dataset_url = 'https://zenodo.org/records/16874898/files/data.zip'\n",
    "dataset_zip = '/content/data.zip'\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "if os.path.exists(dataset_dir) and len(os.listdir(dataset_dir)) > 0:\n",
    "    print(\"‚úì Dataset already exists\")\n",
    "else:\n",
    "    print(\"Downloading dataset (17.9 GB)...\")\n",
    "    print(\"This will take ~15-20 minutes\")\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å progress bar\n",
    "    response = requests.get(dataset_url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(dataset_zip, 'wb') as f:\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True) as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "    \n",
    "    print(\"\\n‚úì Download complete\")\n",
    "    print(\"\\nExtracting dataset...\")\n",
    "    \n",
    "    # –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å\n",
    "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/')\n",
    "    \n",
    "    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å\n",
    "    if os.path.exists('/content/data'):\n",
    "        os.rename('/content/data', dataset_dir)\n",
    "    \n",
    "    # –£–¥–∞–ª–∏—Ç—å –∞—Ä—Ö–∏–≤\n",
    "    os.remove(dataset_zip)\n",
    "    \n",
    "    print(\"‚úì Extraction complete\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "if os.path.exists(dataset_dir):\n",
    "    file_count = sum([len(files) for r, d, files in os.walk(dataset_dir)])\n",
    "    print(f\"\\n‚úì Dataset ready: {file_count} files\")\n",
    "    print(\"\\n‚úÖ Dataset prepared successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ö† ERROR: Dataset not found!\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "SAVE_DIR = '/content/checkpoints'\n",
    "LOG_FILE = '/content/training.log'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Training Configuration\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Epochs:        {EPOCHS}\")\n",
    "print(f\"Batch Size:    {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Save Dir:      {SAVE_DIR}\")\n",
    "print(f\"Log File:      {LOG_FILE}\")\n",
    "print(f\"Device:        {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(\"\\n‚úÖ Configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "**‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ:** \n",
    "- –û–±—É—á–µ–Ω–∏–µ –∑–∞–π–º–µ—Ç ~20 —á–∞—Å–æ–≤ –Ω–∞ GPU T4\n",
    "- –ù–µ –∑–∞–∫—Ä—ã–≤–∞–π—Ç–µ –≤–∫–ª–∞–¥–∫—É –±—Ä–∞—É–∑–µ—Ä–∞\n",
    "- Colab –º–æ–∂–µ—Ç –æ—Ç–∫–ª—é—á–∏—Ç—å—Å—è —á–µ—Ä–µ–∑ 12 —á–∞—Å–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è\n",
    "- –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Starting Training\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nTraining will take ~20 hours on GPU T4\")\n",
    "print(\"Progress will be displayed below...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ\n",
    "!python /content/Voice/train.py \\\n",
    "    --data_dir /content/dataset \\\n",
    "    --batch_size {BATCH_SIZE} \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --lr {LEARNING_RATE} \\\n",
    "    --save_dir {SAVE_DIR} \\\n",
    "    --log_file {LOG_FILE}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  Training Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Training Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é\n",
    "history_file = f\"{SAVE_DIR}/history.json\"\n",
    "if os.path.exists(history_file):\n",
    "    with open(history_file, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # –í—ã–≤–µ—Å—Ç–∏ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    best_val_acc = max(history['val_acc'])\n",
    "    best_epoch = history['val_acc'].index(best_val_acc) + 1\n",
    "    \n",
    "    print(f\"\\nBest Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Best Epoch: {best_epoch}\")\n",
    "    \n",
    "    # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history['train_acc'], label='Train')\n",
    "    axes[0, 0].plot(history['val_acc'], label='Validation')\n",
    "    axes[0, 0].set_title('Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history['train_loss'], label='Train')\n",
    "    axes[0, 1].plot(history['val_loss'], label='Validation')\n",
    "    axes[0, 1].set_title('Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Sensitivity\n",
    "    if 'val_sensitivity' in history:\n",
    "        axes[1, 0].plot(history['val_sensitivity'])\n",
    "        axes[1, 0].set_title('Sensitivity')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Sensitivity (%)')\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Specificity\n",
    "    if 'val_specificity' in history:\n",
    "        axes[1, 1].plot(history['val_specificity'])\n",
    "        axes[1, 1].set_title('Specificity')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Specificity (%)')\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/training_results.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Results plotted successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ö† History file not found. Training may not be complete.\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Creating Deployment Package\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–æ–∑–¥–∞—Ç—å deployment package\n",
    "deployment_dir = '/content/echoflow_v2_deployment'\n",
    "os.makedirs(deployment_dir, exist_ok=True)\n",
    "\n",
    "# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã\n",
    "if os.path.exists(f\"{SAVE_DIR}/best.pt\"):\n",
    "    shutil.copy(f\"{SAVE_DIR}/best.pt\", f\"{deployment_dir}/best.pt\")\n",
    "    print(\"‚úì Copied best.pt\")\n",
    "\n",
    "if os.path.exists(f\"{SAVE_DIR}/history.json\"):\n",
    "    shutil.copy(f\"{SAVE_DIR}/history.json\", f\"{deployment_dir}/history.json\")\n",
    "    print(\"‚úì Copied history.json\")\n",
    "\n",
    "if os.path.exists(LOG_FILE):\n",
    "    shutil.copy(LOG_FILE, f\"{deployment_dir}/training.log\")\n",
    "    print(\"‚úì Copied training.log\")\n",
    "\n",
    "if os.path.exists('/content/training_results.png'):\n",
    "    shutil.copy('/content/training_results.png', f\"{deployment_dir}/results.png\")\n",
    "    print(\"‚úì Copied results.png\")\n",
    "\n",
    "# –°–æ–∑–¥–∞—Ç—å –∞—Ä—Ö–∏–≤\n",
    "shutil.make_archive('/content/echoflow_v2_deployment', 'zip', deployment_dir)\n",
    "print(\"\\n‚úì Created deployment package\")\n",
    "\n",
    "# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–∑–º–µ—Ä\n",
    "package_size = os.path.getsize('/content/echoflow_v2_deployment.zip') / (1024**3)\n",
    "print(f\"‚úì Package size: {package_size:.2f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ Deployment package ready!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–∫–∞—á–∞—Ç—å\n",
    "print(\"\\nDownloading deployment package...\")\n",
    "files.download('/content/echoflow_v2_deployment.zip')\n",
    "print(\"\\n‚úÖ Download started! Check your downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  Model Inference Test\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EchoFlowV2().to(device)\n",
    "\n",
    "if os.path.exists(f\"{SAVE_DIR}/best.pt\"):\n",
    "    checkpoint = torch.load(f\"{SAVE_DIR}/best.pt\", map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(\"‚úì Model loaded successfully\")\n",
    "    \n",
    "    # –ù–∞–π—Ç–∏ —Ç–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª\n",
    "    test_files = []\n",
    "    for root, dirs, files in os.walk('/content/dataset'):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                test_files.append(os.path.join(root, file))\n",
    "                if len(test_files) >= 5:\n",
    "                    break\n",
    "        if len(test_files) >= 5:\n",
    "            break\n",
    "    \n",
    "    if test_files:\n",
    "        print(f\"\\nTesting on {len(test_files)} sample files:\\n\")\n",
    "        \n",
    "        for i, audio_path in enumerate(test_files, 1):\n",
    "            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ\n",
    "            audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
    "            \n",
    "            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "            audio_tensor = torch.FloatTensor(audio).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs = model.predict_proba(audio_tensor)\n",
    "                pred = model.predict(audio_tensor)\n",
    "            \n",
    "            # –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "            label = \"Pathological\" if pred[0] == 1 else \"Healthy\"\n",
    "            confidence = probs[0][pred[0]].item() * 100\n",
    "            \n",
    "            print(f\"{i}. {os.path.basename(audio_path)}\")\n",
    "            print(f\"   Prediction: {label} (confidence: {confidence:.1f}%)\")\n",
    "            print(f\"   Probs: Healthy={probs[0][0].item():.3f}, Pathological={probs[0][1].item():.3f}\\n\")\n",
    "        \n",
    "        print(\"‚úÖ Inference test completed!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö† No test files found\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Model checkpoint not found\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ –ì–æ—Ç–æ–≤–æ!\n",
    "\n",
    "**–ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:**\n",
    "1. ‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –æ–∫—Ä—É–∂–µ–Ω–∏–µ\n",
    "2. ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "3. ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç (17.9 –ì–ë)\n",
    "4. ‚úÖ –û–±—É—á–µ–Ω–∞ –º–æ–¥–µ–ª—å (50 —ç–ø–æ—Ö)\n",
    "5. ‚úÖ –°–æ–∑–¥–∞–Ω deployment package\n",
    "6. ‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å\n",
    "\n",
    "**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**\n",
    "- –ú–æ–¥–µ–ª—å: `/content/checkpoints/best.pt`\n",
    "- –ò—Å—Ç–æ—Ä–∏—è: `/content/checkpoints/history.json`\n",
    "- –õ–æ–≥–∏: `/content/training.log`\n",
    "- –ì—Ä–∞—Ñ–∏–∫–∏: `/content/training_results.png`\n",
    "- Deployment package: —Å–∫–∞—á–∞–Ω\n",
    "\n",
    "**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**\n",
    "1. –†–∞–∑–≤–µ—Ä–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ\n",
    "2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\n",
    "\n",
    "- **GitHub:** https://github.com/izoomlentoboy-creator/Voice\n",
    "- **README:** –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\n",
    "- **QUICKSTART:** –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
    "\n",
    "---\n",
    "\n",
    "**–°–æ–∑–¥–∞–Ω–æ —Å ‚ù§Ô∏è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–∞—Ç–æ–ª–æ–≥–∏–π –≥–æ–ª–æ—Å–∞**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
